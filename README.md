## Elaborado por Jorge Velandia

# Nivel 1

- Ingresar a ./nivel1
- Ejecutar pip install requirements -r requirements.txt(se puede ejecutar creando un virtual environment)
- Cambiar el java_home en el libro notebook.ipynb
- Ejecutar notebook.ipynb con el mismo kernel de spark donde se encuentra instaldo pyspark